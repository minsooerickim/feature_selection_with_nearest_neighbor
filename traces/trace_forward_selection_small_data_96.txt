Enter the input file name: [1, 2, 3, 4, 5, 6]

This data set has 6 features with 500 instances.

Running nearest neighbor with all 6, using "leaving-one-out" evaluation, I get an accuracy of 0.836

1. forward selection
2. backward_elimination

accuracy with 0 features, 0.816

On the 1 level of the search tree
-- Considering adding the 1 feature
---- accuracy with [1] : 0.874
-- Considering adding the 2 feature
---- accuracy with [2] : 0.682
-- Considering adding the 3 feature
---- accuracy with [3] : 0.734
-- Considering adding the 4 feature
---- accuracy with [4] : 0.718
-- Considering adding the 5 feature
---- accuracy with [5] : 0.672
-- Considering adding the 6 feature
---- accuracy with [6] : 0.746

feature subset [1] had the highest accuracy of 0.874
On level 1, I added feature 1 to current set
-----------------------------------------------

On the 2 level of the search tree
-- Considering adding the 2 feature
---- accuracy with [1, 2] : 0.826
-- Considering adding the 3 feature
---- accuracy with [1, 3] : 0.866
-- Considering adding the 4 feature
---- accuracy with [1, 4] : 0.82
-- Considering adding the 5 feature
---- accuracy with [1, 5] : 0.836
-- Considering adding the 6 feature
---- accuracy with [1, 6] : 0.948

feature subset [1, 6] had the highest accuracy of 0.948
On level 2, I added feature 6 to current set
-----------------------------------------------

On the 3 level of the search tree
-- Considering adding the 2 feature
---- accuracy with [1, 6, 2] : 0.904
-- Considering adding the 3 feature
---- accuracy with [1, 6, 3] : 0.94
-- Considering adding the 4 feature
---- accuracy with [1, 6, 4] : 0.904
-- Considering adding the 5 feature
---- accuracy with [1, 6, 5] : 0.938

The best accuracy at this level, [1, 6, 3] : 0.94 was less than the best so far accuracy of 0.948
On level 3, I added feature 3 to current set
-----------------------------------------------

On the 4 level of the search tree
-- Considering adding the 2 feature
---- accuracy with [1, 6, 3, 2] : 0.88
-- Considering adding the 4 feature
---- accuracy with [1, 6, 3, 4] : 0.884
-- Considering adding the 5 feature
---- accuracy with [1, 6, 3, 5] : 0.892

The best accuracy at this level, [1, 6, 3, 5] : 0.892 was less than the best so far accuracy of 0.948
On level 4, I added feature 5 to current set
-----------------------------------------------

On the 5 level of the search tree
-- Considering adding the 2 feature
---- accuracy with [1, 6, 3, 5, 2] : 0.828
-- Considering adding the 4 feature
---- accuracy with [1, 6, 3, 5, 4] : 0.864

The best accuracy at this level, [1, 6, 3, 5, 4] : 0.864 was less than the best so far accuracy of 0.948
On level 5, I added feature 4 to current set
-----------------------------------------------

On the 6 level of the search tree
-- Considering adding the 2 feature
---- accuracy with [1, 6, 3, 5, 4, 2] : 0.836

The best accuracy at this level, [1, 6, 3, 5, 4, 2] : 0.836 was less than the best so far accuracy of 0.948
On level 6, I added feature 2 to current set
-----------------------------------------------

The best features are [1, 6] with accuracy 0.948

Elapsed time: 3.9605610370635986 seconds

